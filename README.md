# Statistical vs. Embedding-Based Models: A Comparative Study in Text Classification. 

This is a Natural Language Processing (NLP) project. 

This study aims to evaluate the effectiveness of statistical models (such as Naive Bayes and SVMs) versus embedding-based models (such as Word2Vec and BERT) in text classification, specifically using the AG News datase. Statistical odels focus on probability and word frequencies, while embedding-based models use deep learning to capture semantic relationships and context. The study seeks to compare the strengths and weaknesses of these approaches in a multi-class news categorisation task, offering insights into the best model choices based on specific classification needs. 
