{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b088da18-782b-4f99-80f6-ee47ba4c7906",
   "metadata": {},
   "source": [
    "# I. Introduction  \n",
    "\n",
    "## 1. Domain-specific area\n",
    "\n",
    "\n",
    "AG News dataste was chosen because of its multi-class problem with four distinct categories, which allows for a richer comparison between models than a binary classificatioin problem would. It is not overly complex, making it feasible to manage within a coursework timeframe, but it is complex enough to highlight the stengths and weaknesses of different models.\n",
    "\n",
    "The news articles cover a broad range of topics, providing a good test for the model's ability to generelaise. Balanced datase: the classes are relatively balanced, which helps in making fair comparisons between the model without heavy biases in the data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fe2dcc-500d-4639-897c-04c1a1639a4f",
   "metadata": {},
   "source": [
    "## 2. Objectives \n",
    "\n",
    "*Outline the goals of exploring both statistical and embedding-based models to understand their effectiveness and applicability in text classification tasks. State any contribution which the results may make to the challenge addressed, supported by relevant literature.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec17547-9ce4-4db8-8170-07cc5e8770f0",
   "metadata": {},
   "source": [
    "## 3. Dataset Description \n",
    "\n",
    "*Identify a suitable dataset which is representative of the challenge and will require attention to all the steps outlined in this assignment. Provide a description of the dataset, its size, data types, the way the data were acquired. Clearly state the source of the dataset. Large technology companies, such as Microsfot, Google, and Amazon, provide a wide variety of datasets. Example: 'Fake and real news' dataset available from the Kaggle official website.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d0ad34-2f45-4c4b-9cbb-7eb9097f8ce2",
   "metadata": {},
   "source": [
    "The dataset that will be used for this project is the AG News Classification dataset. \n",
    "Dataset Link: https://www.kaggle.com/datasets/amananandrai/ag-news-classification-dataset\n",
    "This dataset contains news articles categorised into four classes: World, Sports, Business, and Sci/Tech. The total size is 127,600 news article. This is a news categorisation and a multi-class classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebd7c6b-ea9d-4d30-9d7f-da10283235a7",
   "metadata": {},
   "source": [
    "## 4. Evaluation methodology \n",
    "\n",
    "*Describe the metrics (e.g., Accuracy, Precision, Recall, F1-score) for assessing model performance and discuss how to apply these metrics to cmpare the two methodologies.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004b6b98-cccb-4e05-936a-1ec7b9024118",
   "metadata": {},
   "source": [
    "# II. Implementation\n",
    "\n",
    "*This part of the coursework is the implementation of the project. It includes preprocessing the data, building and testing your classifier and obtaining results.*\n",
    "\n",
    "*The project is expected to be developed using Python language and Jupyter Notebook. Provide well-commented Python code, accompanied by a document describing the following steps:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aadb07-0a40-4d25-8ff8-8287be9fee3d",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing \n",
    "\n",
    "*Convert/store the dataset locally and preprocess the data. Describe the text representation (e.g., Bag of Words, word embedding, etc.) and any preprocessing steps you have applied and why they were needed (e.g., tokenisation, lemmatisation). Address differences in data preparation for statistical models (e.g., frequency tables) versus embedding models (eg., word vectors).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83137e83-1398-4785-b45c-5d89fc1a4aa0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyqt5==5.12.3\n",
      "  Downloading PyQt5-5.12.3-5.12.10-cp35.cp36.cp37.cp38.cp39-none-win_amd64.whl (51.4 MB)\n",
      "     ---------------------------------------- 51.4/51.4 MB 2.4 MB/s eta 0:00:00\n",
      "Collecting PyQt5_sip<13,>=4.19.14\n",
      "  Downloading PyQt5_sip-12.13.0-cp39-cp39-win_amd64.whl (78 kB)\n",
      "     ---------------------------------------- 78.5/78.5 kB ? eta 0:00:00\n",
      "Installing collected packages: PyQt5_sip, pyqt5\n",
      "Successfully installed PyQt5_sip-12.13.0 pyqt5-5.12.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.2.2 requires pyqtwebengine<5.13, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "pip install pyqt5==5.12.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e06ea8e-7ac3-493a-b6be-7489389fb77f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.24.3 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: tensorflow==2.16.1 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from tensorflow==2.16.1) (2.16.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1) (0.2.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1) (21.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1) (0.31.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1) (2.16.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1) (1.14.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1) (63.4.1)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1) (24.3.25)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1) (0.3.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1) (2.28.1)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1) (3.3.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1) (1.6.3)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1) (4.11.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1) (1.16.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1) (0.5.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1) (3.20.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1) (3.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1) (1.64.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1) (2.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1) (2.4.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1) (18.1.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow==2.16.1) (0.37.1)\n",
      "Requirement already satisfied: namex in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow==2.16.1) (0.0.8)\n",
      "Requirement already satisfied: rich in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow==2.16.1) (13.7.1)\n",
      "Requirement already satisfied: optree in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow==2.16.1) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow==2.16.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow==2.16.1) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow==2.16.1) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow==2.16.1) (2022.9.14)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow==2.16.1) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow==2.16.1) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow==2.16.1) (0.7.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.16.1->tensorflow==2.16.1) (3.0.9)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow==2.16.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow==2.16.1) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\cecilia\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow==2.16.1) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user numpy==1.24.3 tensorflow==2.16.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d47b3b5d-9e44-4dc7-abad-21bded5f3438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries \n",
    "\n",
    "import numpy as np  # linear algebra \n",
    "import pandas as pd  # data processing, CSV file \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sb\n",
    "\n",
    "import re \n",
    "import string \n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import preprocessing \n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D, Dropout, Dense, GlobalMaxPool1D, Embedding, Activation \n",
    "from tensorflow.keras.utils import to_categorical \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e0cc19f-1c85-4be7-ba0d-d3db130daa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seed for reproducability \n",
    "from numpy.random import seed \n",
    "seed(10)\n",
    "tf.random.set_seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8973f01a-7cc6-4e8e-9667-4face135fb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cecilia\\OneDrive\\3. SIM-UOL UNI DEGREE\\Y3 Sem 2\\3. Natural Language processing\\4. Midterm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf6a7bb-1b19-4339-80bd-01bad6451abd",
   "metadata": {},
   "source": [
    "## 6. Baseline performance \n",
    "\n",
    "*Describe and justify the baseline against which you are going to compare the performance of your chosen approach. This can be an already published baseline (e.g. cited in the literature) or the results of a basic algorithm that you implement yourself. The baseline should represnt a meaningful benchmark for comparison*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da98437-2f42-431e-ae39-e5b7dc4aba11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d20317-f1ff-4782-b95e-3e1f6250f05d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c79da623-40d4-47b6-8e97-be8272101980",
   "metadata": {},
   "source": [
    "## 7. Comparative Classification approach \n",
    "\n",
    "*Implement both a traditional statistical model and a modern deep learning model. Build a classifier using the appropriate Python library. Detail the architecture, training, and optimisation processes of each, emphasising their strengths and weaknesses in the context of the chosen dataset. Clearly compare the performance of the two models. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8331fc8-0f9b-40fe-b340-0a810f8ffdf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bb703f-904b-468e-aaa0-cba14f2a1b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be101066-0653-4b4c-b5ff-e1d4fbd246a5",
   "metadata": {},
   "source": [
    "## 8. Programming style \n",
    "\n",
    "*Ensure all code is clear and well-commented. Documentation should include detailed explanations of the rationale behind model choices, parameter settings, and any specific libraries or tools used.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0524ed4c-ae6e-41eb-b77d-6d1ab860ac67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87f8f3d-0ac7-404b-8ac5-80eee35e5be4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14e9d4bf-2294-47da-8e3b-18c1c99eae7f",
   "metadata": {},
   "source": [
    "# III. Conclusions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5348fe17-8613-4958-90ce-da9fc2076b9e",
   "metadata": {},
   "source": [
    "## 9. Performance Analysis & Comparative Discussion \n",
    "\n",
    "*Present and analyse the results for both models. Use visualisations to compare performance across different classes and discuss any significant findings. Critically evaluate the advantages and disadvantages of statistical and embedding-based models based on the result. Discuss scenarios where one might be preferred over the other and hypothesise reasons for observed performance disparities.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63cb2ad-0561-4ac4-ad5d-35ffb708aaef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66eaf7e-2142-4f53-9384-45f08ca2a370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1298f777-3e66-40ed-9c81-de61f482fc27",
   "metadata": {},
   "source": [
    "## 10. Project Summary and Reflections \n",
    "\n",
    "*Reflect on the learning experience, the practicality of each model type, and their potential applications in real-world scenarios. Describe its contributions to the problem area and discuss the extent to which your solution is transferable to other domain-specific areas. Suggest improvements and future research directions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846a8262-a804-4afc-83b5-154e1d68a59d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
